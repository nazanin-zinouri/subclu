{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ead9d3ed",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "Check whether GPUs are available/usable in current python environment.\n",
    "\n",
    "Originally ran this notebook in instance:\n",
    "- `tensorflow-2-3-20210615`\n",
    "\n",
    "\n",
    "# Debugging notes\n",
    "## Make sure to set the correct venv/kernel in your notebook\n",
    "The default `python 3` might not have the correct drivers.\n",
    "<br>Instead, might need to manually set it to:\n",
    "<br>`Python [conda env:root]`\n",
    "\n",
    "## Sometimes the best fix is `sudo reboot`\n",
    "When in doubt, open a terminal and do `sudo reboot`.\n",
    "\n",
    "For some reason, the NVIDIA drivers might not be loaded properly after shutting down a VM instance from the GUI:\n",
    "- https://console.cloud.google.com/ai-platform/notebooks/list/instances?project=data-prod-165221\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62b0763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ad772b",
   "metadata": {},
   "source": [
    "# Imports & notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73290d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002efc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\t\tv 3.7.10\n",
      "===\n",
      "tensorflow\tv: 2.3.3\n",
      "tensorflow_text\tv: 2.3.0\n",
      "subclu\t\tv: 0.1.1\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import subclu\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, notebook_display_config, print_lib_versions,\n",
    ")\n",
    "\n",
    "\n",
    "print_lib_versions([tf, tensorflow_text, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bdf2137",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825eb0a",
   "metadata": {},
   "source": [
    "# Check GPUs recognized by Tensorflow/python\n",
    "\n",
    "NOTE: `GPU`s and `XLA_GPU`s are recognized as two different device types.\n",
    "\n",
    "https://www.tensorflow.org/xla\n",
    "> **XLA: Optimizing Compiler for Machine Learning**\n",
    "> XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes.\n",
    "> \n",
    "> The results are improvements in speed and memory usage: e.g. in BERT MLPerf submission using 8 Volta V100 GPUs using XLA has achieved a ~7x performance improvement and ~5x batch size improvement\n",
    "\n",
    "Other sources\n",
    "- https://stackoverflow.com/questions/52943489/what-is-xla-gpu-and-xla-cpu-for-tensorflow\n",
    "\n",
    "---\n",
    "\n",
    "Expected output for an `XLA_GPU`:\n",
    "```\n",
    "name: \"/device:XLA_GPU:0\"\n",
    "device_type: \"XLA_GPU\"\n",
    "memory_limit: 17179869184\n",
    "locality {\n",
    "}\n",
    "incarnation: 3534006815138276117\n",
    "physical_device_desc: \"device: XLA_GPU device\"\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c8e688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Built with CUDA? True\n",
      "\n",
      "GPUs\n",
      "===\n",
      "Num GPUs Available: 0\n",
      "GPU details:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "l_phys_gpus = (\n",
    "    tf.config.list_physical_devices('GPU') +\n",
    "    tf.config.list_physical_devices('XLA_GPU')\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nBuilt with CUDA? {tf.test.is_built_with_cuda()}\"\n",
    "    f\"\\n\\nGPUs\\n===\"\n",
    "    f\"\\nNum GPUs Available: {len(l_phys_gpus)}\"\n",
    "    f\"\\nGPU details:\\n{l_phys_gpus}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a48ec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Built with CUDA? True\n",
      "\n",
      "All devices:\n",
      "===\n",
      "Num devices: 2\n",
      "Details:\n",
      "[   name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3865335962365996498\n",
      ",\n",
      "    name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7842223851287837074\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "l_all_local_devices = device_lib.list_local_devices()\n",
    "print(\n",
    "    f\"\\nBuilt with CUDA? {tf.test.is_built_with_cuda()}\"\n",
    "    f\"\\n\\nAll devices:\\n===\"\n",
    "    f\"\\nNum devices: {len(l_all_local_devices)}\"\n",
    "    f\"\\nDetails:\"\n",
    ")\n",
    "pprint(l_all_local_devices, indent=4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f6deb7",
   "metadata": {},
   "source": [
    "# Check NVIDIA CLI\n",
    "\n",
    "First, do we even see the GPUs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64225048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:04.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)\n"
     ]
    }
   ],
   "source": [
    "!lspci | grep 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84500f0d",
   "metadata": {},
   "source": [
    "Then, are they recognized by the nvidia-smi tool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f107bdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 30 04:01:29 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   55C    P0    18W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee080b",
   "metadata": {},
   "source": [
    "## Debug nvidia drivers\n",
    "\n",
    "If `nvidia-smi` doesn't detect the drivers, we might need to reinstall them.\n",
    "\n",
    "- https://towardsdatascience.com/troubleshooting-gcp-cuda-nvidia-docker-and-keeping-it-running-d5c8b34b6a4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc37632e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii  libnvidia-container-tools             1.4.0-1                       amd64        NVIDIA container runtime library (command-line tools)\n",
      "ii  libnvidia-container1:amd64            1.4.0-1                       amd64        NVIDIA container runtime library\n",
      "ii  nvidia-container-runtime              3.5.0-1                       amd64        NVIDIA container runtime\n",
      "ii  nvidia-container-toolkit              1.5.0-1                       amd64        NVIDIA container runtime hook\n",
      "ii  nvidia-docker2                        2.6.0-1                       all          nvidia-docker CLI wrapper\n"
     ]
    }
   ],
   "source": [
    "!dpkg -l | grep nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f103aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dpkg -l | grep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86bff43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmesg: read kernel buffer failed: Operation not permitted\n"
     ]
    }
   ],
   "source": [
    "!dmesg | grep NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a11bed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting... Done\n",
      "Full Text Search... Done\n"
     ]
    }
   ],
   "source": [
    "!apt search nvidia-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b1728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m71"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
