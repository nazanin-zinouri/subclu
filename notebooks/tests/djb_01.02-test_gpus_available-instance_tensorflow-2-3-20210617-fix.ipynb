{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674f1a56",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "Check whether GPUs are available/usable in current python environment.\n",
    "\n",
    "\n",
    "# Debugging notes\n",
    "## Make sure to set the correct venv/kernel in your notebook\n",
    "The default `python 3` might not have the correct drivers.\n",
    "<br>Instead, might need to manually set it to:\n",
    "<br>`Python [conda env:root]`\n",
    "\n",
    "## Sometimes the best fix is `sudo reboot`\n",
    "When in doubt, open a terminal and do `sudo reboot`.\n",
    "\n",
    "For some reason, the NVIDIA drivers might not be loaded properly after shutting down a VM instance from the GUI:\n",
    "- https://console.cloud.google.com/ai-platform/notebooks/list/instances?project=data-prod-165221\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334f32ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d168d88",
   "metadata": {},
   "source": [
    "# Imports & notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b4faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df606f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'jinja2' has no attribute 'PackageLoader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f6f0b547ee11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubclu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m from subclu.utils.eda import (\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0msetup_logging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnotebook_display_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_lib_versions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/home/david.bermejo/repos/subreddit_clustering_i18n/subclu/utils/eda.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStyler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;31m# from tqdm.auto import tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mStyler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m     64\u001b[0m     \u001b[0mHelps\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSeries\u001b[0m \u001b[0maccording\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mHTML\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mCSS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/formats/style.py\u001b[0m in \u001b[0;36mStyler\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPackageLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pandas\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"io/formats/templates\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjinja2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim_blocks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"html.tpl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'jinja2' has no attribute 'PackageLoader'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import subclu\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, notebook_display_config, print_lib_versions,\n",
    ")\n",
    "\n",
    "\n",
    "print_lib_versions([tf, tensorflow_text, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae361d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927b028",
   "metadata": {},
   "source": [
    "# Check GPUs/XLA_GPUs recognized by Tensorflow/python\n",
    "\n",
    "NOTE: `GPU`s and `XLA_GPU`s are recognized as two different device types.\n",
    "\n",
    "https://www.tensorflow.org/xla\n",
    "> **XLA: Optimizing Compiler for Machine Learning**\n",
    "> XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes.\n",
    "> \n",
    "> The results are improvements in speed and memory usage: e.g. in BERT MLPerf submission using 8 Volta V100 GPUs using XLA has achieved a ~7x performance improvement and ~5x batch size improvement\n",
    "\n",
    "Other sources\n",
    "- https://stackoverflow.com/questions/52943489/what-is-xla-gpu-and-xla-cpu-for-tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191278f",
   "metadata": {},
   "source": [
    "## What device gets used for calculations?\n",
    "\n",
    "It should be `GPU` or `XLA_GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ae9ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n",
      "CPU times: user 46.2 ms, sys: 21.7 ms, total: 67.9 ms\n",
      "Wall time: 115 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631eb3d",
   "metadata": {},
   "source": [
    "## List devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd87357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Built with CUDA? True\n",
      "\n",
      "GPUs\n",
      "===\n",
      "Num GPUs Available: 0\n",
      "GPU details:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "l_phys_gpus = (\n",
    "    tf.config.list_physical_devices('GPU') +\n",
    "    tf.config.list_physical_devices('XLA_GPU')\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nBuilt with CUDA? {tf.test.is_built_with_cuda()}\"\n",
    "    f\"\\n\\nGPUs\\n===\"\n",
    "    f\"\\nNum GPUs Available: {len(l_phys_gpus)}\"\n",
    "    f\"\\nGPU details:\\n{l_phys_gpus}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f981f122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Built with CUDA? True\n",
      "\n",
      "All devices:\n",
      "===\n",
      "Num devices: 2\n",
      "Details:\n",
      "[   name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1302600850232263420\n",
      ",\n",
      "    name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17225786062779179402\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "l_all_local_devices = device_lib.list_local_devices()\n",
    "print(\n",
    "    f\"\\nBuilt with CUDA? {tf.test.is_built_with_cuda()}\"\n",
    "    f\"\\n\\nAll devices:\\n===\"\n",
    "    f\"\\nNum devices: {len(l_all_local_devices)}\"\n",
    "    f\"\\nDetails:\"\n",
    ")\n",
    "pprint(l_all_local_devices, indent=4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d3b0f2",
   "metadata": {},
   "source": [
    "# Check NVIDIA CLI\n",
    "\n",
    "First, do we even see the GPUs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c4f886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:04.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)\n",
      "00:05.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)\n"
     ]
    }
   ],
   "source": [
    "!lspci | grep 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b6cb9",
   "metadata": {},
   "source": [
    "Then, are they recognized by the nvidia-smi tool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7301cf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 30 05:57:22 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   68C    P0    31W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   70C    P0    22W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a320dfc",
   "metadata": {},
   "source": [
    "## Debug nvidia drivers\n",
    "\n",
    "If `nvidia-smi` doesn't detect the drivers, we might need to reinstall them.\n",
    "\n",
    "- https://towardsdatascience.com/troubleshooting-gcp-cuda-nvidia-docker-and-keeping-it-running-d5c8b34b6a4c\n",
    "\n",
    "Getting nothing from `cuda` is bad... sigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a2b0711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii  libnvidia-container-tools             1.4.0-1                       amd64        NVIDIA container runtime library (command-line tools)\n",
      "ii  libnvidia-container1:amd64            1.4.0-1                       amd64        NVIDIA container runtime library\n",
      "ii  nvidia-container-runtime              3.5.0-1                       amd64        NVIDIA container runtime\n",
      "ii  nvidia-container-toolkit              1.5.1-1                       amd64        NVIDIA container runtime hook\n",
      "ii  nvidia-docker2                        2.6.0-1                       all          nvidia-docker CLI wrapper\n"
     ]
    }
   ],
   "source": [
    "!dpkg -l | grep nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57adc913",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dpkg -l | grep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5b6c10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmesg: read kernel buffer failed: Operation not permitted\n"
     ]
    }
   ],
   "source": [
    "!dmesg | grep NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d6e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt search nvidia-driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aedf75",
   "metadata": {},
   "source": [
    "## CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "072bce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Thu_Jun_11_22:26:38_PDT_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.194\n",
      "Build cuda_11.0_bu.TC445_37.28540450_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223c4569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading channels: failed\n",
      "\n",
      "NotWritableError: The current user does not have write permissions to a required path.\n",
      "  path: /opt/conda/pkgs/cache/497deca9.json\n",
      "  uid: 1002\n",
      "  gid: 1003\n",
      "\n",
      "If you feel that permissions on this path are set incorrectly, you can manually\n",
      "change them by executing\n",
      "\n",
      "  $ sudo chown 1002:1003 /opt/conda/pkgs/cache/497deca9.json\n",
      "\n",
      "In general, it's not advisable to use 'sudo conda'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda search cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92ebf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading channels: failed\n",
      "\n",
      "NotWritableError: The current user does not have write permissions to a required path.\n",
      "  path: /opt/conda/pkgs/cache/497deca9.json\n",
      "  uid: 1002\n",
      "  gid: 1003\n",
      "\n",
      "If you feel that permissions on this path are set incorrectly, you can manually\n",
      "change them by executing\n",
      "\n",
      "  $ sudo chown 1002:1003 /opt/conda/pkgs/cache/497deca9.json\n",
      "\n",
      "In general, it's not advisable to use 'sudo conda'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda search cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae8b56f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sudo: conda: command not found\n"
     ]
    }
   ],
   "source": [
    "!sudo conda search cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de117cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading channels: failed\n",
      "\n",
      "NotWritableError: The current user does not have write permissions to a required path.\n",
      "  path: /opt/conda/pkgs/cache/497deca9.json\n",
      "  uid: 1002\n",
      "  gid: 1003\n",
      "\n",
      "If you feel that permissions on this path are set incorrectly, you can manually\n",
      "change them by executing\n",
      "\n",
      "  $ sudo chown 1002:1003 /opt/conda/pkgs/cache/497deca9.json\n",
      "\n",
      "In general, it's not advisable to use 'sudo conda'.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this call works on mac, but fails on VM because of permissions\n",
    "!conda search cudnn --platform linux-64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d9d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m71"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
