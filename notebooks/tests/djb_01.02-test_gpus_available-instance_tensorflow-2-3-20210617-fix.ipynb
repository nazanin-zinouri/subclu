{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91ecd1fa",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "Check whether GPUs are available/usable in current python environment.\n",
    "\n",
    "\n",
    "# Debugging notes\n",
    "## Make sure to set the correct venv/kernel in your notebook\n",
    "The default `python 3` might not have the correct drivers.\n",
    "<br>Instead, might need to manually set it to:\n",
    "<br>`Python [conda env:root]`\n",
    "\n",
    "## Sometimes the best fix is `sudo reboot`\n",
    "When in doubt, open a terminal and do `sudo reboot`.\n",
    "\n",
    "For some reason, the NVIDIA drivers might not be loaded properly after shutting down a VM instance from the GUI:\n",
    "- https://console.cloud.google.com/ai-platform/notebooks/list/instances?project=data-prod-165221\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f7a9473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa050e1d",
   "metadata": {},
   "source": [
    "# Imports & notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46c6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5daf630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\t\tv 3.7.10\n",
      "===\n",
      "tensorflow\tv: 2.3.0\n",
      "tensorflow_text\tv: 2.3.0\n",
      "subclu\t\tv: 0.1.1\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import subclu\n",
    "from subclu.utils.eda import (\n",
    "    setup_logging, notebook_display_config, print_lib_versions,\n",
    ")\n",
    "\n",
    "\n",
    "print_lib_versions([tf, tensorflow_text, subclu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd64ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b925f97",
   "metadata": {},
   "source": [
    "# Check GPUs/XLA_GPUs recognized by Tensorflow/python\n",
    "\n",
    "NOTE: `GPU`s and `XLA_GPU`s are recognized as two different device types.\n",
    "\n",
    "https://www.tensorflow.org/xla\n",
    "> **XLA: Optimizing Compiler for Machine Learning**\n",
    "> XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that can accelerate TensorFlow models with potentially no source code changes.\n",
    "> \n",
    "> The results are improvements in speed and memory usage: e.g. in BERT MLPerf submission using 8 Volta V100 GPUs using XLA has achieved a ~7x performance improvement and ~5x batch size improvement\n",
    "\n",
    "Other sources\n",
    "- https://stackoverflow.com/questions/52943489/what-is-xla-gpu-and-xla-cpu-for-tensorflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080de85",
   "metadata": {},
   "source": [
    "## What device gets used for calculations?\n",
    "\n",
    "It should be `GPU` or `XLA_GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a967bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n",
      "CPU times: user 37.2 ms, sys: 28.4 ms, total: 65.6 ms\n",
      "Wall time: 666 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Create some tensors\n",
    "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f757b",
   "metadata": {},
   "source": [
    "## List devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968d2eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Built with CUDA? True\n",
      "\n",
      "GPUs\n",
      "===\n",
      "Num GPUs Available: 0\n",
      "GPU details:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "l_phys_gpus = (\n",
    "    tf.config.list_physical_devices('GPU') +\n",
    "    tf.config.list_physical_devices('XLA_GPU')\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"\\nBuilt with CUDA? {tf.test.is_built_with_cuda()}\"\n",
    "    f\"\\n\\nGPUs\\n===\"\n",
    "    f\"\\nNum GPUs Available: {len(l_phys_gpus)}\"\n",
    "    f\"\\nGPU details:\\n{l_phys_gpus}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad48334b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Built with CUDA? True\n",
      "\n",
      "All devices:\n",
      "===\n",
      "Num devices: 2\n",
      "Details:\n",
      "[   name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3071036896695927534\n",
      ",\n",
      "    name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 6148380577737378169\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "l_all_local_devices = device_lib.list_local_devices()\n",
    "print(\n",
    "    f\"\\nBuilt with CUDA? {tf.test.is_built_with_cuda()}\"\n",
    "    f\"\\n\\nAll devices:\\n===\"\n",
    "    f\"\\nNum devices: {len(l_all_local_devices)}\"\n",
    "    f\"\\nDetails:\"\n",
    ")\n",
    "pprint(l_all_local_devices, indent=4,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd80ba3",
   "metadata": {},
   "source": [
    "# Check NVIDIA CLI\n",
    "\n",
    "First, do we even see the GPUs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cb63fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:04.0 3D controller: NVIDIA Corporation TU104GL [Tesla T4] (rev a1)\n"
     ]
    }
   ],
   "source": [
    "!lspci | grep 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef44bdf",
   "metadata": {},
   "source": [
    "Then, are they recognized by the nvidia-smi tool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "401fdc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 30 15:16:27 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   60C    P0    19W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c87d0",
   "metadata": {},
   "source": [
    "## Debug nvidia drivers\n",
    "\n",
    "If `nvidia-smi` doesn't detect the drivers, we might need to reinstall them.\n",
    "\n",
    "- https://towardsdatascience.com/troubleshooting-gcp-cuda-nvidia-docker-and-keeping-it-running-d5c8b34b6a4c\n",
    "\n",
    "Getting nothing from `cuda` is bad... sigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f323dd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ii  libnvidia-container-tools             1.4.0-1                       amd64        NVIDIA container runtime library (command-line tools)\n",
      "ii  libnvidia-container1:amd64            1.4.0-1                       amd64        NVIDIA container runtime library\n",
      "ii  nvidia-container-runtime              3.5.0-1                       amd64        NVIDIA container runtime\n",
      "ii  nvidia-container-toolkit              1.5.1-1                       amd64        NVIDIA container runtime hook\n",
      "ii  nvidia-docker2                        2.6.0-1                       all          nvidia-docker CLI wrapper\n"
     ]
    }
   ],
   "source": [
    "!dpkg -l | grep nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1783730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!dpkg -l | grep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "798baab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dmesg: read kernel buffer failed: Operation not permitted\n"
     ]
    }
   ],
   "source": [
    "!dmesg | grep NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb932fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt search nvidia-driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e855e04",
   "metadata": {},
   "source": [
    "## CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4859c84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\n",
      "Built on Thu_Jun_11_22:26:38_PDT_2020\n",
      "Cuda compilation tools, release 11.0, V11.0.194\n",
      "Build cuda_11.0_bu.TC445_37.28540450_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc1a67",
   "metadata": {},
   "source": [
    "### Check `cudnn` & `cudatoolkit` versions in conda\n",
    "\n",
    "This doens't work because we don't have the right permissions. We might not need it, though, because by default the VMs created by Google don't have these drivers installed via conda either. \n",
    "\n",
    "Unclear what's missing or what changes that breaks the driver detection when installing the requirements from my project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6d41053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda search cudatoolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a790c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda search cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c04ca294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo conda search cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df51940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this call works on mac, but fails on VM because of permissions\n",
    "# !conda search cudnn --platform linux-64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0914f86",
   "metadata": {},
   "source": [
    "# Check libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db4fc8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bc32344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc68f61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m71"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
